{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo: Transform and Inverse Transform Pipeline\n",
    "This notebook demonstrates the process of transforming and inverse-transforming a dataset using the `DataLoaderTransformer` and `ScalableVGMMNormalizer` pipeline from the `src` folder.\n",
    "\n",
    "We will:\n",
    "1. Load the configuration file.\n",
    "2. Load and preprocess the dataset.\n",
    "3. Apply the transformation and save the transformed data.\n",
    "4. Apply the inverse transformation and save the inverse-transformed data.\n",
    "5. Measure and display the time taken for each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "import yaml\n",
    "import pandas as pd\n",
    "\n",
    "# Add the src directory to the Python module search path\n",
    "sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(\"__file__\"), \"..\")))\n",
    "# Import necessary libraries and set up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data_loader import DataLoaderTransformer  # Importing from src folder\n",
    "from src.vgmm_normalizer import ScalableVGMMNormalizer  # Importing from src folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Configuration:\n",
      "{'DataLoaderTransformer': {'input_path': '../data/input_50K.csv', 'output_parquet_path': '../data/input_converted_50K.parquet', 'n_workers': 1, 'threads_per_worker': 2, 'memory_limit': '6GB', 'spill_dir': './tmp/dask-spill', 'target_partitions': 10}, 'ScalableVGMMNormalizer': {'n_clusters': 10, 'eps': 0.005, 'weight_concentration_prior_type': 'dirichlet_process', 'weight_concentration_prior': 0.001, 'max_iter': 100, 'n_init': 1, 'random_state': 42}, 'continuous_columns': ['Amount']}\n"
     ]
    }
   ],
   "source": [
    "# Define the function to load configuration\n",
    "def load_config(config_path):\n",
    "    \"\"\"\n",
    "    Load the configuration file from a YAML path.\n",
    "\n",
    "    Parameters:\n",
    "        config_path (str): Path to the YAML configuration file.\n",
    "\n",
    "    Returns:\n",
    "        dict: Parsed configuration dictionary.\n",
    "    \"\"\"\n",
    "    with open(config_path, \"r\") as file:\n",
    "        config = yaml.safe_load(file)\n",
    "    return config\n",
    "\n",
    "# Specify the path to your configuration file\n",
    "config_path = \"../config/demo.yaml\"  # Adjust this path to your actual config file location\n",
    "\n",
    "# Load the configuration\n",
    "config = load_config(config_path)\n",
    "data_loader_config = config[\"DataLoaderTransformer\"]\n",
    "\n",
    "# Display the loaded configuration\n",
    "print(\"Loaded Configuration:\")\n",
    "print(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize DataLoaderTransformer\n",
    "The `DataLoaderTransformer` is responsible for loading, preprocessing, and managing data transformations. In this step, we initialize it with the configuration settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dask client initialized with 1 workers, 2 threads per worker, memory limit 6GB, and spill-to-disk at ./tmp/dask-spill.\n",
      "Dask Dashboard is running at: http://127.0.0.1:8787/status\n"
     ]
    }
   ],
   "source": [
    "# Initialize the DataLoaderTransformer\n",
    "data_loader = DataLoaderTransformer(config=data_loader_config)\n",
    "\n",
    "if data_loader.client:\n",
    "    print(f\"Dask Dashboard is running at: {data_loader.client.dashboard_link}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measure Time and Perform the Pipeline Steps\n",
    "We will now perform the following steps:\n",
    "1. Load and preprocess the dataset.\n",
    "2. Apply the transformation and save the transformed data.\n",
    "3. Apply the inverse transformation and save the inverse-transformed data.\n",
    "\n",
    "We will measure the time taken for each step and display it at the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV converted to Parquet and saved at ../data/input_converted_50K.parquet\n",
      "Initial transformations applied to the DataFrame.\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to store timing for each step\n",
    "timing = {}\n",
    "\n",
    "# Step 1: Load and preprocess data\n",
    "start_time = time.time()\n",
    "df = data_loader.load_and_convert_data()\n",
    "df = data_loader.apply_transformations(df)\n",
    "timing[\"Load and Preprocess\"] = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Apply VGMM Transformation\n",
    "start_time = time.time()\n",
    "continuous_columns = config.get(\"continuous_columns\")\n",
    "transformed_df, normalizers = data_loader.apply_vgmm_transformation(df, continuous_columns)\n",
    "timing[\"Transformation\"] = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved CSV to ../data/output/transformed_data.csv\n",
      "Saved Parquet to ../data/output/transformed_data.parquet\n"
     ]
    }
   ],
   "source": [
    "# Utility function to save output files\n",
    "def save_output(df, output_dir, filename_base):\n",
    "    \"\"\"\n",
    "    Save a Dask DataFrame in both CSV and Parquet formats in a specified directory.\n",
    "\n",
    "    Parameters:\n",
    "        df (dd.DataFrame): Dask DataFrame to save.\n",
    "        output_dir (str): Directory where to save the output files.\n",
    "        filename_base (str): Base name of the output files (without extension).\n",
    "    \"\"\"\n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Save to CSV\n",
    "    csv_path = os.path.join(output_dir, f\"{filename_base}.csv\")\n",
    "    df.compute().to_csv(csv_path, index=False)\n",
    "    print(f\"Saved CSV to {csv_path}\")\n",
    "\n",
    "    # Save to Parquet\n",
    "    parquet_path = os.path.join(output_dir, f\"{filename_base}.parquet\")\n",
    "    df.to_parquet(parquet_path, engine=\"pyarrow\", write_index=False)\n",
    "    print(f\"Saved Parquet to {parquet_path}\")\n",
    "\n",
    "# Step 3: Save transformed data\n",
    "start_time = time.time()\n",
    "input_dir = os.path.dirname(data_loader_config[\"input_path\"])\n",
    "output_dir = os.path.join(input_dir, \"output\")\n",
    "save_output(transformed_df, output_dir, \"transformed_data\")\n",
    "timing[\"Save Transformed Data\"] = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Apply Inverse Transformation\n",
    "start_time = time.time()\n",
    "inverse_transformed_df = data_loader.apply_inverse_transformation(\n",
    "    transformed_df, continuous_columns, normalizers\n",
    ")\n",
    "inverse_transformed_only = inverse_transformed_df[[f\"{col}_inverse_transformed\" for col in continuous_columns]]\n",
    "timing[\"Inverse Transformation\"] = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved CSV to ../data/output/inverse_transformed_data.csv\n",
      "Saved Parquet to ../data/output/inverse_transformed_data.parquet\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Save inverse-transformed data\n",
    "start_time = time.time()\n",
    "save_output(inverse_transformed_only, output_dir, \"inverse_transformed_data\")\n",
    "timing[\"Save Inverse Transformed Data\"] = time.time() - start_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display Timing Results\n",
    "Finally, we display the time taken for each step in the pipeline. This helps in understanding the performance of the pipeline and identifying any bottlenecks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Timing Results:\n",
      "                               Time (s)\n",
      "Load and Preprocess            0.348949\n",
      "Transformation                 0.098540\n",
      "Save Transformed Data          1.706664\n",
      "Inverse Transformation         0.003953\n",
      "Save Inverse Transformed Data  1.407375\n"
     ]
    }
   ],
   "source": [
    "# Display timing results\n",
    "timing_df = pd.DataFrame.from_dict(timing, orient=\"index\", columns=[\"Time (s)\"])\n",
    "print(\"\\nTiming Results:\")\n",
    "print(timing_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Amount</th>\n",
       "      <th>Amount_transformed</th>\n",
       "      <th>Amount_prob_0</th>\n",
       "      <th>Amount_prob_1</th>\n",
       "      <th>Amount_prob_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.61</td>\n",
       "      <td>-0.062408</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.169768</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>197.04</td>\n",
       "      <td>0.037085</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.169768</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23.25</td>\n",
       "      <td>0.005746</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Amount  Amount_transformed  Amount_prob_0  Amount_prob_1  Amount_prob_2\n",
       "0   14.61           -0.062408            1.0            0.0            0.0\n",
       "1    1.00           -0.169768            1.0            0.0            0.0\n",
       "2  197.04            0.037085            0.0            1.0            0.0\n",
       "3    1.00           -0.169768            1.0            0.0            0.0\n",
       "4   23.25            0.005746            1.0            0.0            0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"../data/output/transformed_data.csv\").head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Amount_inverse_transformed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>197.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Amount_inverse_transformed\n",
       "0                       14.61\n",
       "1                        1.00\n",
       "2                      197.04\n",
       "3                        1.00\n",
       "4                       23.25"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(\"../data/output/inverse_transformed_data.csv\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>197.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Amount\n",
       "0   14.61\n",
       "1    1.00\n",
       "2  197.04\n",
       "3    1.00\n",
       "4   23.25"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(config[\"DataLoaderTransformer\"][\"input_path\"]).head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vgm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
